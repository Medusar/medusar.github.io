<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Medusar&#39;s playground</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Medusar的个人博客">
<meta property="og:type" content="website">
<meta property="og:title" content="Medusar's playground">
<meta property="og:url" content="http://blog.onlycatch.com/index.html">
<meta property="og:site_name" content="Medusar's playground">
<meta property="og:description" content="Medusar的个人博客">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Medusar's playground">
<meta name="twitter:description" content="Medusar的个人博客">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="/blog/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
  <link href="/blog/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/blog/css/style.css" type="text/css">
  

</head>

<body>
  <div id="container">
    <header id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <a id="main-nav-toggle" class="nav-icon" href="javascript:;"></a>
      <a id="logo" class="logo" href="/"></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/blog/archives">Archives</a>
        
          <a class="main-nav-link" href="/blog/booklist">Booklist</a>
        
          <a class="main-nav-link" href="/blog/others">Resources</a>
        
          <a class="main-nav-link" href="/blog/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        <div id="search-form-wrap">
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://blog.onlycatch.com"></form>
        </div>
      </nav>
    </div>
  </div>
</header>
    <section id="main" class="outer">
      <article id="post-cap-and-base" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/cap-and-base/">CAP理论和BASE理论</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/blog/cap-and-base/" class="article-date">
  <time datetime="2016-01-27T12:23:46.000Z" itemprop="datePublished">2016-01-27</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/blog/categories/coding/">编程</a>
  </div>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="CAP_u7406_u8BBA"><a href="#CAP_u7406_u8BBA" class="headerlink" title="CAP理论"></a>CAP理论</h2><p>一个分布式系统不可能同时满足CAP三个需求，最多只能同时满足其中的两项。<br>C(consistency)一致性，A(avaliability)可用性，P(Partition tolerance)分区容错性。</p>
<h3 id="u4E00_u81F4_u6027_28consistency_29"><a href="#u4E00_u81F4_u6027_28consistency_29" class="headerlink" title="一致性(consistency)"></a>一致性(consistency)</h3><p>与数据库事务的一致性不同，分布式系统中的一致性指的是数据在多个副本之间是否能够保持一致。即某个节点的数据发生了变动，需要将数据更新同步到其他节点上。</p>
<h3 id="u53EF_u7528_u6027_28avalibility_29"><a href="#u53EF_u7528_u6027_28avalibility_29" class="headerlink" title="可用性(avalibility)"></a>可用性(avalibility)</h3><p>系统提供的服务必须一直处于可用的状态。对于用户的每一个操作请求总是能在<strong>有限时间内返回结果</strong>。</p>
<h3 id="u5206_u533A_u5BB9_u9519_u6027_28partition_tolerence_29"><a href="#u5206_u533A_u5BB9_u9519_u6027_28partition_tolerence_29" class="headerlink" title="分区容错性(partition tolerence)"></a>分区容错性(partition tolerence)</h3><p>分布式系统在遇到任何网络分区故障的时候，仍然需要能够保证对外提供满足一致性和可用性的服务。除非是整个网络环境都发生了故障。即网络分区出现故障不应该影响整个系统的运行。</p>
<p>根据CAP理论，在我们设计分布式系统的时候，无法同时满足CAP三个需求，所以就需要进行取舍。<br>对于分布式系统来说，分区容错性可以说是一个最基本的要求，因为分布式中必然存在子网络。所以一般我们都会在C和A之间寻求平衡。</p>
<h2 id="BASE_u7406_u8BBA"><a href="#BASE_u7406_u8BBA" class="headerlink" title="BASE理论"></a>BASE理论</h2><p>BA: Basically Avaliable(基本可用)<br>S:Soft State(软状态)<br>E:Eventually consistent(最终一致性)</p>
<p>BASE是对CAP中一致性和可用性权衡的结果，核心思想是，即使无法做到强一致性，但是每个应用都可以根据自身的业务特点，采取适当的方式使系统达到最终一致性(E)。</p>
<h3 id="u57FA_u672C_u53EF_u7528__28Basically_avaliable_29"><a href="#u57FA_u672C_u53EF_u7528__28Basically_avaliable_29" class="headerlink" title="基本可用 (Basically avaliable)"></a>基本可用 (Basically avaliable)</h3><p>分布式系统出现不可预知故障的时候，允许损失部分可用性。包括性能损失(响应时间增加）和功能损失（降级）</p>
<h3 id="u8F6F_u72B6_u6001_uFF08soft_state_29"><a href="#u8F6F_u72B6_u6001_uFF08soft_state_29" class="headerlink" title="软状态（soft state)"></a>软状态（soft state)</h3><p>允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性。即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。</p>
<h3 id="u6700_u7EC8_u4E00_u81F4_u6027_28eventually_consitent_29"><a href="#u6700_u7EC8_u4E00_u81F4_u6027_28eventually_consitent_29" class="headerlink" title="最终一致性(eventually consitent)"></a>最终一致性(eventually consitent)</h3><p>系统中所有的数据副本，在经过一段时间的同步之后，最终达到一个一致的状态。强调的是最终一致，而不是实时一致。</p>

      
    </div>
    
    
      <footer class="article-footer">
        
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/BASE/">BASE</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/CAP/">CAP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/分布式系统/">分布式系统</a></li></ul>

      </footer>
    
  </div>
  
</article>


    
      <article id="post-zero-copy-in-netty" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/zero-copy-in-netty/">Netty中的零拷贝</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/blog/zero-copy-in-netty/" class="article-date">
  <time datetime="2016-01-26T12:20:44.000Z" itemprop="datePublished">2016-01-26</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/blog/categories/coding/">编程</a>
  </div>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p>Netty中的零拷贝与我们传统理解的零拷贝不太一样。<br>传统的零拷贝指的是数据传输过程中，不需要CPU进行数据的拷贝。主要是数据在用户空间与内核中间之间的拷贝。</p>
<h2 id="u4F20_u7EDF_u610F_u4E49_u7684_u96F6_u62F7_u8D1D"><a href="#u4F20_u7EDF_u610F_u4E49_u7684_u96F6_u62F7_u8D1D" class="headerlink" title="传统意义的零拷贝"></a>传统意义的零拷贝</h2><blockquote>
<p>Zero-Copy describes computer operations in which the CPU does not perform the task of copying data from one memory area to another.\</p>
</blockquote>
<p>在发送数据的时候，传统的实现方式是：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">File.read(bytes)</span><br><span class="line">Socket.send(bytes)</span><br></pre></td></tr></table></figure></p>
<p>这种方式需要四次数据拷贝和四次上下文切换：</p>
<ol>
<li>数据从磁盘读取到内核的read buffer</li>
<li>数据从内核缓冲区拷贝到用户缓冲区</li>
<li>数据从用户缓冲区拷贝到内核的socket buffer</li>
<li>数据从内核的socket buffer拷贝到网卡接口的缓冲区</li>
</ol>
<p>明显上面的第二步和第三步是没有必要的，通过java的FileChannel.transferTo方法，可以避免上面两次多余的拷贝（当然这需要底层操作系统支持）</p>
<ol>
<li>调用transferTo,数据从文件由DMA引擎拷贝到内核read buffer</li>
<li>接着DMA从内核read buffer将数据拷贝到网卡接口buffer</li>
</ol>
<p>上面的两次操作都不需要CPU参与，所以就达到了零拷贝。</p>
<h2 id="Netty_u4E2D_u7684_u96F6_u62F7_u8D1D"><a href="#Netty_u4E2D_u7684_u96F6_u62F7_u8D1D" class="headerlink" title="Netty中的零拷贝"></a>Netty中的零拷贝</h2><p>Netty中也用到了FileChannel.transferTo方法，所以Netty的零拷贝也包括上面将的操作系统级别的零拷贝。除此之外，在ByteBuf的实现上，Netty也提供了零拷贝的一些实现。</p>
<p>关于ByteBuffer，Netty提供了两个接口:</p>
<ol>
<li>ByteBuf</li>
<li>ByteBufHolder</li>
</ol>
<p>对于ByteBuf，Netty提供了多种实现：</p>
<ol>
<li>Heap ByteBuf:直接在堆内存分配</li>
<li>Direct ByteBuf：直接在内存区域分配而不是堆内存</li>
<li>CompositeByteBuf：组合Buffer</li>
</ol>
<h3 id="Direct_Buffers"><a href="#Direct_Buffers" class="headerlink" title="Direct Buffers"></a>Direct Buffers</h3><p>直接在内存区域分配空间，而不是在堆内存中分配。如果使用传统的堆内存分配，当我们需要将数据通过socket发送的时候，就需要从堆内存拷贝到直接内存，然后再由直接内存拷贝到网卡接口层。<br>Netty提供的直接Buffer，直接将数据分配到内存空间，从而避免了数据的拷贝，实现了零拷贝。</p>
<h3 id="Composite_Buffers"><a href="#Composite_Buffers" class="headerlink" title="Composite Buffers"></a>Composite Buffers</h3><p>传统的ByteBuffer，如果需要将两个ByteBuffer中的数据组合到一起，我们需要首先创建一个size=size1+size2大小的新的数组，然后将两个数组中的数据拷贝到新的数组中。但是使用Netty提供的组合ByteBuf，就可以避免这样的操作，因为CompositeByteBuf并没有真正将多个Buffer组合起来，而是保存了它们的引用，从而避免了数据的拷贝，实现了零拷贝。</p>
<h3 id="u5BF9_u4E8EFileChannel-transferTo_u7684_u4F7F_u7528"><a href="#u5BF9_u4E8EFileChannel-transferTo_u7684_u4F7F_u7528" class="headerlink" title="对于FileChannel.transferTo的使用"></a>对于FileChannel.transferTo的使用</h3><p>Netty中使用了FileChannel的transferTo方法，该方法依赖于操作系统实现零拷贝。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>Netty的零拷贝体现在三个方面：</p>
<ol>
<li>Netty的接收和发送ByteBuffer采用DIRECT BUFFERS，使用堆外直接内存进行Socket读写，不需要进行字节缓冲区的二次拷贝。如果使用传统的堆内存（HEAP BUFFERS）进行Socket读写，JVM会将堆内存Buffer拷贝一份到直接内存中，然后才写入Socket中。相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。</li>
<li>Netty提供了组合Buffer对象，可以聚合多个ByteBuffer对象，用户可以像操作一个Buffer那样方便的对组合Buffer进行操作，避免了传统通过内存拷贝的方式将几个小Buffer合并成一个大的Buffer。</li>
<li>Netty的文件传输采用了transferTo方法，它可以直接将文件缓冲区的数据发送到目标Channel，避免了传统通过循环write方式导致的内存拷贝问题。</li>
</ol>
<h2 id="u53C2_u8003_u8D44_u6599"><a href="#u53C2_u8003_u8D44_u6599" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a href="http://my.oschina.net/plucury/blog/192577" target="_blank" rel="external">http://my.oschina.net/plucury/blog/192577</a></li>
<li><a href="http://www.infoq.com/cn/articles/netty-high-performance" target="_blank" rel="external">http://www.infoq.com/cn/articles/netty-high-performance</a></li>
<li>《Netty in Action V5_meap》</li>
</ol>

      
    </div>
    
    
      <footer class="article-footer">
        
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/netty/">netty</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/零拷贝/">零拷贝</a></li></ul>

      </footer>
    
  </div>
  
</article>


    
      <article id="post-zero-copy" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/zero-copy/">零拷贝</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/blog/zero-copy/" class="article-date">
  <time datetime="2016-01-26T12:19:26.000Z" itemprop="datePublished">2016-01-26</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/blog/categories/coding/">编程</a>
  </div>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p>在看kafka的时候又提到了零拷贝，之前netty中也提到过零拷贝，今天就来看一下什么是零拷贝，零拷贝的又来以及如何使用。</p>
<h2 id="u539F_u7406_u4ECB_u7ECD"><a href="#u539F_u7406_u4ECB_u7ECD" class="headerlink" title="原理介绍"></a>原理介绍</h2><p>网络服务器都存在网络数据传输的问题，在服务器上，文件都是存放在磁盘上，当有请求到来的时候，需要将磁盘上的文件发送到网络中。</p>
<h3 id="u4F20_u7EDF_u7684_u6570_u636E_u53D1_u9001_u8FC7_u7A0B"><a href="#u4F20_u7EDF_u7684_u6570_u636E_u53D1_u9001_u8FC7_u7A0B" class="headerlink" title="传统的数据发送过程"></a>传统的数据发送过程</h3><p>在传统情况下，java中要实现这个过程需要调用下面两个方法：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">File.read(fileDesc, buf, len);</span><br><span class="line">Socket.send(socket, buf, len);</span><br></pre></td></tr></table></figure></p>
<p>即首先调用read方法，将磁盘文件读取到内存中；然后调用Socket的send方法，将字节数据发送出去。</p>
<p>java代码很简单，但是这个过程在操作系统层面却被分成了四个步骤：</p>
<ol>
<li>将数据从硬盘拷贝到内核空间中的缓冲区</li>
<li>将数据从内核缓冲区拷贝到用户空间缓冲区</li>
<li>将数据从用户空间缓冲区再拷回到内核缓冲区（Socket Buffer)</li>
<li>将数据从内核缓冲区拷贝到网卡缓冲区(NIC Buffer）</li>
</ol>
<p>可以看到，上面四个步骤中进行了四次数据拷贝，并且还涉及到了四次上下文切换。</p>
<p>下图描述的更清楚：<br>数据拷贝：<br><img src="http://7xo4v8.com1.z0.glb.clouddn.com/%40%2Fima%2Ffigure1.gif" alt="传统方式的数据拷贝"><br>上下文切换：<br><img src="http://7xo4v8.com1.z0.glb.clouddn.com/%40%2Fima%2Ffigure2.gif" alt="传统拷贝方式的上下文切换"><br>Step 1. read()方法会造成一次上下文切换，即从用户态切换到内核态。在底层会调用sys_read()方法（或者其他等同的方法）来读取文件。第一次拷贝由DMA引擎完成，从磁盘读取数据然后保存在内核空间缓冲区。<br>Step 2. 被请求的数据从read buffer 拷贝到用户缓冲区，此时read()方法返回。read()方法返回会造成上下文从内核态切换回用户态。此时数据被存放在用户空间缓冲区。<br>Step 3. socket的send()方法会使上下文从用户态切换到内核态。第三次拷贝发生了，数据被从用户缓冲区拷贝回到内核缓冲区。但是这次数据不再是放在read buffer中了，而是放到了不同的地方:Socket Buffer中。<br>Step 4. send()方法返回，造成第四次上下文切换。第四次拷贝异步并独立地将数据从内核缓冲区拷贝到协议引擎。</p>
<h3 id="u96F6_u62F7_u8D1D_u7684_u5B9E_u73B0"><a href="#u96F6_u62F7_u8D1D_u7684_u5B9E_u73B0" class="headerlink" title="零拷贝的实现"></a>零拷贝的实现</h3><p>零拷贝通过消除了不必要的数据拷贝过程而达到提高性能的目的。<br>上面的传统方式来说，第二步和第三步的拷贝是不必要的，即数据可以直接从内核缓冲区的read buffer拷贝到内核缓冲区的 socket buffer。实现这个功能的是java中的FileChannal的transferTo()方法。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span><br><span class="line">  * &lt;p&gt; This method is potentially much more efficient than a simple loop</span><br><span class="line">     * that reads from this channel and writes to the target channel.  Many</span><br><span class="line">     * operating systems can transfer bytes directly from the filesystem cache</span><br><span class="line">     * to the target channel without actually copying them.  &lt;/p&gt;</span><br><span class="line">**/</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">transferTo</span><span class="params">(<span class="keyword">long</span> position, <span class="keyword">long</span> count, WritableByteChannel target)</span></span>;</span><br></pre></td></tr></table></figure></p>
<p>该方法将数据从文件管道传输到指定的可写的channel。在内部是依赖与操作系统对于零拷贝的支持。linux系统中，提供了一个sendfile()方法，它可以将数据从一个文件描述符转移到另一个文件描述符。关于sendfile可以参考这里：<a href="http://man7.org/linux/man-pages/man2/sendfile.2.html" target="_blank" rel="external">sendfile API</a></p>
<p>使用transferTo之后，数据的拷贝过程如下：<br><img src="http://7xo4v8.com1.z0.glb.clouddn.com/%40%2Fima%2Ffigure3.gif" alt="transferTo"><br>上下文切换如下：<br><img src="http://7xo4v8.com1.z0.glb.clouddn.com/%40%2Fima%2Ffigure4.gif" alt="神下文切换"></p>
<ol>
<li>transferTo()方法导致DMA引擎将数据从磁盘拷贝到内核缓冲区的read buffer中，然后又从read buffer中拷贝到相关的socke buffer中。</li>
<li>接下来DMA引擎将数据从内核缓冲区的socket buffer中拷贝到协议引擎。</li>
</ol>
<p>虽然仍然有三次拷贝(虽然之后一次需要CPU介入，即第二次），但是对于上下文切换来说却减少到了两次，即在调用transferTo的时候从用户态切换到内核态，等transferTo完成之后，再从内核态切换回用户态。但这仍然没有达到零拷贝的目的。</p>
<p>如果底层的网卡接口支持gather操作的话，我们还可以进一步减少内存拷贝。在linux内核2.4以及以后的版本中，对socket缓冲区描述符进行了调整以满足该需求。这种方式不仅减少了上下文切换也减少了需要CPU接入的数据拷贝。从用户使用的角度来讲并没有什么不同，但是底层实现却变了：</p>
<ol>
<li>transferTo()方法促使DMA引擎将数据从文件中拷贝到内核缓冲区</li>
<li>数据不再拷贝到socket buffer中，相反，只有包含关于数据的位置和长度的信息的描述符被追加到了套接字缓冲区。DMA引擎直接把数据从内核缓冲区传输到协议引擎，从而消除了剩下的最后一次 CPU 拷贝。<br>如下图：<br><img src="http://7xo4v8.com1.z0.glb.clouddn.com/%40%2Fima%2Ffigure5.gif" alt="改进后的transferTo"></li>
</ol>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><ol>
<li>零拷贝并不是没有任何数据拷贝过程，而是将需要CPU参与的数据拷贝过程都消除掉。</li>
<li>零拷贝在java中是通过FileChannel的transferTo实现的，但是它是依赖与所在操作系统对于零拷贝的支持。</li>
<li>linux系统中提供了sendfile()方法来支持将数据从一个文件描述符转移到另外一个，从而实现零拷贝的目的。</li>
<li>零拷贝的演变过程：首先消除了数据在内核空间与用户空间之间的拷贝，但是仍然需要在内核态中进行一次拷贝（从read buffer到socket buffer)。如果网卡接口支持gather操作，那么可以直接从read buffer拷贝到网卡接口buffer。</li>
<li>零拷贝仍然需要经历两次数据拷贝：1）将数据从磁盘拷贝到内核缓冲区2）将数据从内核缓冲区拷贝到网卡接口数据缓冲区。零拷贝只需要两次上下文切换，即调用transferTo的时候从用户态转移到内核态，transferTo返回的时候从内核态转移回用户态。</li>
</ol>
<blockquote>
<p>Zero-Copy describes computer operations in which the CPU does not perform the task of copying data from one memory area to another.</p>
</blockquote>
<h3 id="sendfile"><a href="#sendfile" class="headerlink" title="sendfile"></a>sendfile</h3><p>sendfile支持在文件描述符之间拷贝数据，由于拷贝是在内核中进行，所以比组合使用read()和write()方法更有效，因为read,write需要将数据拷贝到用户空间。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sendfile() copies data between one file descriptor and another.</span><br><span class="line">      Because this copying is <span class="keyword">done</span> within the kernel, sendfile() is more</span><br><span class="line">      efficient than the combination of <span class="built_in">read</span>(<span class="number">2</span>) and write(<span class="number">2</span>), <span class="built_in">which</span> would</span><br><span class="line">      require transferring data to and from user space</span><br></pre></td></tr></table></figure></p>
<h2 id="u53C2_u8003_u8D44_u6599"><a href="#u53C2_u8003_u8D44_u6599" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a href="https://www.ibm.com/developerworks/linux/library/j-zerocopy/" target="_blank" rel="external">https://www.ibm.com/developerworks/linux/library/j-zerocopy/</a></li>
<li><a href="http://man7.org/linux/man-pages/man2/sendfile.2.html" target="_blank" rel="external">http://man7.org/linux/man-pages/man2/sendfile.2.html</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy1/（更详细）" target="_blank" rel="external">http://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy1/（更详细）</a></li>
<li><a href="https://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy2/（更详细）" target="_blank" rel="external">https://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy2/（更详细）</a><br>DMA:direct memory access 直接内存访问</li>
</ol>

      
    </div>
    
    
      <footer class="article-footer">
        
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/网络/">网络</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/计算机基础/">计算机基础</a></li></ul>

      </footer>
    
  </div>
  
</article>


    
      <article id="post-database-transaction" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/database-transaction/">数据库事务</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/blog/database-transaction/" class="article-date">
  <time datetime="2016-01-26T12:18:10.000Z" itemprop="datePublished">2016-01-26</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/blog/categories/coding/">编程</a>
  </div>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="u4EC0_u4E48_u662F_u6570_u636E_u5E93_u4E8B_u52A1"><a href="#u4EC0_u4E48_u662F_u6570_u636E_u5E93_u4E8B_u52A1" class="headerlink" title="什么是数据库事务"></a>什么是数据库事务</h2><p>数据库事务指的是对数据库进行的一些列操作集合。这些集合中的操作要么全部执行成功，要么全部回滚。</p>
<h2 id="u6570_u636E_u5E93_u4E8B_u52A1_u7684ACID_u7279_u6027"><a href="#u6570_u636E_u5E93_u4E8B_u52A1_u7684ACID_u7279_u6027" class="headerlink" title="数据库事务的ACID特性"></a>数据库事务的ACID特性</h2><p>数据库事务必须满足ACID四个特性。</p>
<p>A(atomic):原子性。即事务必须是一个原子的操作序列单元。事务中包含的各项操作在一次执行过程中，要么全部执行，要么全部不执行。<br>C(consistent):一致性，即事务的执行不能破坏数据库的完整性和一致性。一个事务在执行前和执行后，数据库都必须处于一致性状态。就是说，事务执行的结果必须使数据库从一个一致性状态转移到另一个一致性状态。<br>I(isolated):隔离性,在并发环境中，并发的事务是相互隔离的，一个事务的执行不被其他事务干扰。<br>D(durable):持久性。即一个事务一旦提交，它对数据库中对于数据状态的变更就是永久性的。也就是说，一旦某个事务成功结束，那么它对数据库的变更就必须被永久保存下来。</p>
<h2 id="u6570_u636E_u5E93_u4E8B_u52A1_u9694_u79BB_u7EA7_u522B"><a href="#u6570_u636E_u5E93_u4E8B_u52A1_u9694_u79BB_u7EA7_u522B" class="headerlink" title="数据库事务隔离级别"></a>数据库事务隔离级别</h2><p>数据库事务有四种隔离级别:Read Uncommited,read commited,repeatable read,serialization。意思就是 未提交读，提交读，可重复读，序列化四个级别。四个级别的隔离程度依次升高，并发性也就依次降低。</p>
<p>Read Uncommited: 看字面意思就可以理解，即读取到了未提交的数据。即事务A修改了数据但是还没提交，此时事务B进来读取了该数据，而读取的数据正好是A刚修改却还没提交的。这就叫 read uncommited。该隔离级别下，事务B可以读取到事务A未提交的修改。这种情况叫做”脏读”</p>
<p>Read Commited: 该隔离级别下，事务B不能读取到事务A未提交的修改，只能等到事务A提交了之后，事务B才能读取到A做的修改。但是该级别下仍然存在一个问题:”不可重复读”。即事务B分两次读取数据，第一次在事务A提交之前，第二次在事务A提交之后，如果事务A对数据进行了更改，那么事务B的两次读取结果是不相同的。也就是说，不能重复读取。</p>
<p>Repeatable read:可重复读，就是说允许事务B两次读取同一组数据，并且所得结果一样。该隔离级别解决了不可重复读的问题，但是仍然存在“幻读”的问题。</p>
<p>Serialization:序列化，能够解决幻读的问题，这是最高的隔离级别。</p>
<p>幻读：第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。</p>
<h2 id="u4E0D_u540C_u9694_u79BB_u7EA7_u522B_u5BF9_u6BD4"><a href="#u4E0D_u540C_u9694_u79BB_u7EA7_u522B_u5BF9_u6BD4" class="headerlink" title="不同隔离级别对比"></a>不同隔离级别对比</h2><table>
<thead>
<tr>
<th>事务隔离级别</th>
<th>脏读</th>
<th>不可重复读</th>
<th>幻读</th>
</tr>
</thead>
<tbody>
<tr>
<td>READ_UNCOMMITTED</td>
<td>允许</td>
<td>允许</td>
<td>允许</td>
</tr>
<tr>
<td>READ_COMMITTED</td>
<td>禁止</td>
<td>允许</td>
<td>允许</td>
</tr>
<tr>
<td>REPEATABLE_READ</td>
<td>禁止</td>
<td>禁止</td>
<td>允许</td>
</tr>
<tr>
<td>SERIALIZABLE</td>
<td>禁止</td>
<td>禁止</td>
<td>禁止</td>
</tr>
</tbody>
</table>
<p>事务隔离级别越高，就越能保证数据的完整性和一致性，但同时对于并发性能的影响也就越大。<br>在MySQL中，InnoDB默认的隔离级别是Repeatable read。</p>
<h2 id="u6269_u5C55_u9605_u8BFB"><a href="#u6269_u5C55_u9605_u8BFB" class="headerlink" title="扩展阅读"></a>扩展阅读</h2><ol>
<li><a href="http://my.oschina.net/huangyong/blog/160012" target="_blank" rel="external">http://my.oschina.net/huangyong/blog/160012</a></li>
<li><a href="http://my.oschina.net/huangyong/blog/159852" target="_blank" rel="external">http://my.oschina.net/huangyong/blog/159852</a></li>
<li><a href="https://en.wikipedia.org/wiki/Database_transaction" target="_blank" rel="external">https://en.wikipedia.org/wiki/Database_transaction</a></li>
</ol>

      
    </div>
    
    
      <footer class="article-footer">
        
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/数据库/">数据库</a></li></ul>

      </footer>
    
  </div>
  
</article>


    
      <article id="post-kafka-selflearning-00" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/kafka-selflearning-00/">Kafka学习笔记之初见</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/blog/kafka-selflearning-00/" class="article-date">
  <time datetime="2016-01-25T12:07:48.000Z" itemprop="datePublished">2016-01-25</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/blog/categories/coding/">编程</a>
  </div>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p>kafka是一个高性能的分布式消息系统。高水平扩展和高吞吐量。支持动态扩容，由LinkedIn用Scala编写而成。</p>
<h2 id="kafka_u4E0E_u5176_u4ED6_u6D88_u606F_u7CFB_u7EDF_u5BF9_u6BD4"><a href="#kafka_u4E0E_u5176_u4ED6_u6D88_u606F_u7CFB_u7EDF_u5BF9_u6BD4" class="headerlink" title="kafka与其他消息系统对比"></a>kafka与其他消息系统对比</h2><p>flume,storm,spark,elesticsearch都能与kafka集成。<br><img src="http://7xo4v8.com1.z0.glb.clouddn.com/kafka.png" alt="kafka与其他消息系统的对比"></p>
<ol>
<li>kafka使用的协议为仿AMQP协议。</li>
<li>kafka不支持事务，activeMQ支持</li>
<li>kafka支持动态扩容，集群，负载均衡。</li>
</ol>
<p><a href="https://en.wikipedia.org/wiki/Advanced_Message_Queuing_Protocol" target="_blank" rel="external">AMQP协议</a>:<a href="http://langyu.iteye.com/blog/759663" target="_blank" rel="external">http://langyu.iteye.com/blog/759663</a></p>
<h2 id="kafka_u7684_u6D88_u8D39_u8005_u7F16_u7A0B_u6A21_u578B"><a href="#kafka_u7684_u6D88_u8D39_u8005_u7F16_u7A0B_u6A21_u578B" class="headerlink" title="kafka的消费者编程模型"></a>kafka的消费者编程模型</h2><ol>
<li>分区消费模型</li>
<li>组消费模型<h3 id="u5206_u533A_u6D88_u8D39_u6A21_u578B"><a href="#u5206_u533A_u6D88_u8D39_u6A21_u578B" class="headerlink" title="分区消费模型"></a>分区消费模型</h3>缺点：</li>
<li>需要自己处理各种异常情况</li>
<li>需要自己管理消息偏移量以实现消息传递的各种语义</li>
</ol>
<h3 id="u6D88_u606F_u4F20_u9012_u7684_u8BED_u4E49"><a href="#u6D88_u606F_u4F20_u9012_u7684_u8BED_u4E49" class="headerlink" title="消息传递的语义"></a>消息传递的语义</h3><ol>
<li>至少一次：发送者向消费者至少发送一次（可能会重复）</li>
<li>至多一次：发送者向消费者至多发送一次（可能会丢）</li>
<li>有且仅有一次：发送者与消费者的关系一对一。<h3 id="u7EC4_u6D88_u8D39_u6A21_u578B"><a href="#u7EC4_u6D88_u8D39_u6A21_u578B" class="headerlink" title="组消费模型"></a>组消费模型</h3></li>
<li>不需要自己处理异常情况，不需要自己管理offset</li>
<li>只能实现默认的kafka至少一次的消息传递语义</li>
</ol>
<h2 id="kafka_u7684_u751F_u4EA7_u8005_u7F16_u7A0B_u6A21_u578B"><a href="#kafka_u7684_u751F_u4EA7_u8005_u7F16_u7A0B_u6A21_u578B" class="headerlink" title="kafka的生产者编程模型"></a>kafka的生产者编程模型</h2><h3 id="u540C_u6B65_u751F_u4EA7_u6A21_u578B"><a href="#u540C_u6B65_u751F_u4EA7_u6A21_u578B" class="headerlink" title="同步生产模型"></a>同步生产模型</h3><p>生产者发送消息后需要等待kafka集群的确认消息，直到收到确认消息或者超过最大投递次数。</p>
<p>特点：</p>
<ol>
<li>低消息丢失率</li>
<li>高消息重复率（网络原因导致回复确认没收到）</li>
<li>高延迟<h3 id="u5F02_u6B65_u751F_u4EA7_u6A21_u578B"><a href="#u5F02_u6B65_u751F_u4EA7_u6A21_u578B" class="headerlink" title="异步生产模型"></a>异步生产模型</h3>生产者先把消息发送到客户端的缓冲队列，队列中的消息会被打包一起发送到kafka服务器。<br>特点：</li>
<li>高消息丢失率（无确认机制，发送端队列满）</li>
<li>高发送性能</li>
<li>低延迟</li>
</ol>

      
    </div>
    
    
      <footer class="article-footer">
        
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/Kafka/">Kafka</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/大数据/">大数据</a></li></ul>

      </footer>
    
  </div>
  
</article>


    
      <article id="post-kafka-selflearning-02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/kafka-selflearning-02/">Kafka学习笔记之高性能设计</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/blog/kafka-selflearning-02/" class="article-date">
  <time datetime="2016-01-25T12:03:52.000Z" itemprop="datePublished">2016-01-25</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/blog/categories/coding/">编程</a>
  </div>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="u6301_u4E45_u5316"><a href="#u6301_u4E45_u5316" class="headerlink" title="持久化"></a>持久化</h2><p>kafka非常依赖文件系统进行消息存储和缓存。大部分人会认为“磁盘很慢”，所以很多人会怀疑持久化是否能够提供很好的性能。实际上磁盘速度的快慢与磁盘的使用方式有着很大关系，设计好的磁盘结构通常会很快。</p>
<p>对于磁盘的线性读写操作在很多系统中都进行了大量优化，在某些情况下，对于磁盘的顺序访问甚至比对于内存的随机访问还要快！</p>
<p>很多现代操作系统都大量使用主存做磁盘缓存，一个现代操作系统可以将内存中的所有剩余空间用作磁盘缓存，而当内存回收的时候几乎没有性能损失。所有的磁盘读写都会经过这个统一的缓存。哪怕使用directI/O，这个特性也很难被关闭，所以如果某个进程维护了一份进程内缓存，那么这部分数据很可能也在操作系统的页面缓存中存在。</p>
<p>由于kafka是基于JVM的，并且任何与java内存使用打过交道的人都知道两件事：</p>
<ol>
<li>对象的内存开销非常高，通常是实际要存储数据大小的两倍</li>
<li>随着数据的增加，java的垃圾收集也会越来越频繁并且缓慢<br>基于此，使用文件系统，同时依赖页面缓存就比使用其他数据结构和维护内存缓存更有吸引力：</li>
<li>不使用进程内缓存，就腾出了内存空间，可以用来存放页面缓存的空间几乎可以翻倍。</li>
<li>如果kafka重启，进行内缓存就会丢失，但是使用操作系统的页面缓存依然可以继续使用。</li>
</ol>
<p>kafka如此频繁利用页面缓存，如果内存大小不够了怎么办？kafka会将数据写入到持久化日志中而不是刷新到磁盘。实际上它只是转移到了内核的页面缓存。</p>
<h2 id="u6570_u636E_u7ED3_u6784"><a href="#u6570_u636E_u7ED3_u6784" class="headerlink" title="数据结构"></a>数据结构</h2><p><a href="http://kafka.apache.org/documentation.html#design_constanttime" target="_blank" rel="external">http://kafka.apache.org/documentation.html#design_constanttime</a></p>
<h2 id="u5927_u91CF_u7684_u5C0FIO_u64CD_u4F5C_u548C_u5927_u91CF_u7684_u5B57_u8282_u62F7_u8D1D"><a href="#u5927_u91CF_u7684_u5C0FIO_u64CD_u4F5C_u548C_u5927_u91CF_u7684_u5B57_u8282_u62F7_u8D1D" class="headerlink" title="大量的小IO操作和大量的字节拷贝"></a>大量的小IO操作和大量的字节拷贝</h2><p>除了上面说的磁盘读写影响性能之外，另外两个影响性能的就是：</p>
<ol>
<li>大量的IO操作</li>
<li>大量的字节拷贝</li>
</ol>
<h3 id="u5927_u91CF_u7684_u5C0FIO_u64CD_u4F5C"><a href="#u5927_u91CF_u7684_u5C0FIO_u64CD_u4F5C" class="headerlink" title="大量的小IO操作"></a>大量的小IO操作</h3><p>对于消息服务端来说，写操作是很频繁的，为了避免这个问题，kafka的协议是基于一种“消息集合”的抽象，它允许网络请求将消息集中发送而不是每次发送一条消息。服务端同样，也是一次性将一组消息写入日志，消费者也是每次取一大块。</p>
<p>这样做能够产生更大的网络数据包，更大的连续磁盘操作以及连续的内存块，这些都使得kafka更容易将大量随机消息编程线性的写操作。</p>
<h3 id="u5927_u91CF_u7684_u5B57_u8282_u62F7_u8D1D"><a href="#u5927_u91CF_u7684_u5B57_u8282_u62F7_u8D1D" class="headerlink" title="大量的字节拷贝"></a>大量的字节拷贝</h3><p>kafka消费者，生产者还有服务端使用的日志格式都是一样的。这样做的好处就是能够为网络传输数据块提供最大的优化。</p>
<p>一般来讲，将文件中的数据转移到Socket需要经过以下几步：</p>
<ol>
<li>操作系统将数据从磁盘读到内核空间的页面缓存中</li>
<li>应用程序从内核空间将数据读取到用户空间</li>
<li>应用程序将数据重新写入到内核空间中的socket缓存中</li>
<li>操作系统将数据从socket缓存中拷贝到网卡缓存中（网卡缓存中的数据将被发送到网络中）</li>
</ol>
<p>上面的过程经过了四次拷贝和两次系统调用，明显这是不高效的。<br>通过使用sendfile API,允许操作系统直接从页面缓存将数据发送到网络，就减少了不必要的拷贝，只有最后一步：将数据拷贝到网卡缓存是必须的。</p>
<p>假设某个Topic有多个消费者，使用上面的零拷贝技术，数据只会被拷贝一次进入页面缓存，每次消费都可以被重复使用。这样就避免了每次读的时候都将数据存到内存中然后拷贝到内核空间。</p>
<h2 id="u7AEF_u5230_u7AEF_u6279_u91CF_u538B_u7F29"><a href="#u7AEF_u5230_u7AEF_u6279_u91CF_u538B_u7F29" class="headerlink" title="端到端批量压缩"></a>端到端批量压缩</h2><p>在很多情况下，系统的瓶颈不是CPU而是带宽。所以数据压缩就很重要。<br>可以每个消息都压缩，但是压缩率相对很低。所以kafka使用了批量压缩，即将多个消息一起压缩而不是单个消息压缩。<br>kafka允许使用递归的消息集合，批量的消息可以通过压缩的形式传输并且在日志中也可以保持压缩格式，直到被消费者解压缩。<br>kafka支持Gzip和Snappy压缩协议。</p>
<h2 id="u751F_u4EA7_u8005"><a href="#u751F_u4EA7_u8005" class="headerlink" title="生产者"></a>生产者</h2><h3 id="u8D1F_u8F7D_u5747_u8861"><a href="#u8D1F_u8F7D_u5747_u8861" class="headerlink" title="负载均衡"></a>负载均衡</h3><p>生产者直接将数据发送到broker中，中间不会经过任何路由层。<br>为了达到这个目的，所有的kafka节点都能在任何时候回答是否服务器可以用以及主题分区的leader机器在哪里等问题，以便于生产者正确的发送数据。</p>
<p>生产者客户端控制着消息发往哪个分区。可以通过随机负载均衡或者其他分区语义功能来实现。kafka提供了分区语义接口允许用户指定一个用户哈希分析的字段。</p>
<h3 id="u5F02_u6B65_u53D1_u9001"><a href="#u5F02_u6B65_u53D1_u9001" class="headerlink" title="异步发送"></a>异步发送</h3><p>为了实现批量发送，kafka需要在内存中积累数据，以便于在单次请求中发送足够大的数据。可以通过配置消息数量不超过某个值或者等待时间不超过某个值来进行控制。</p>
<h2 id="u6D88_u8D39_u8005"><a href="#u6D88_u8D39_u8005" class="headerlink" title="消费者"></a>消费者</h2><p>消费者通过指定log的offset来获取消息，每次取回一块以指定的offset开始的消息块。</p>
<h3 id="u63A8_vs-__u62C9"><a href="#u63A8_vs-__u62C9" class="headerlink" title="推 vs. 拉"></a>推 vs. 拉</h3><p>在kafka中，消息是被消费者推到broker的，然后被生产者拉过来。<br>一些以日志为中心的系统，比如Scibe和Flume则允许将数据推向下游。</p>
<p>推和拉各有利弊，推模式中，由于是broker控制数据传输速度，目标是以尽可能提高消费者的消息消费率，push模式中，如果消费者消费速度跟不上推的速度，消费者就处于过载状态。而使用拉模式，消费者可以根据自己的处理能力控制拉取消息的速度。</p>
<p>传统拉模式的缺点是：如果服务端没有消息，消费者将会进入循环等待，直到新的数据到达。为了避免这个问题，kafka提供了配置参数，允许消费者请求进入long poll 等待，直到有数据到达。（。。。表示不太懂）</p>
<h3 id="u6D88_u8D39_u8005_u4F4D_u7F6E"><a href="#u6D88_u8D39_u8005_u4F4D_u7F6E" class="headerlink" title="消费者位置"></a>消费者位置</h3><p>在很多消息系统中，服务端是需要维护消息的消费状态的，即当消息投递给消费者之后，服务端要么立即记录下来，要么等待消费端的确认。</p>
<p>如果broker每次将消息投递出去就将消息状态置为“已消费”，那么如果消费者没有成功消费该消息（可能消费者宕机了或者请求超时了等），那消息就相当于丢失了。为了避免这个问题，很多系统增加了确认机制，当消息发送出去的时候，被置为“已发送”状态而不是“已消费”，当收到消费者的确认信息之后，才将消息状态置为“已消费”。</p>
<p>但这会有新的问题，首先，如果消费者消费了消息但是在发送确认信息之前出错了，那么消息将会被消费两次。其次是性能问题，这样一来broker就必须维护很多状态（每条信息一组状态）。另外还需要处理很多其他问题，例如:消息发送出去了但是没有收到确认该怎么办？</p>
<p>kafka的做法是这样的：<br>Topic被分成多个完全有序的分区，任何时候，任意一个分区都只有一个消费者消费。这意味着在每个分区中的消费者位置都是一个整数：下一个即将消费的offset值。这样就使得消息确认变得很容易。<br>另外还有一个好处：消费者可以故意将offset置为一个很老的值，然后重新消费数据。</p>
<h3 id="u79BB_u7EBF_u6570_u636E_u52A0_u8F7D"><a href="#u79BB_u7EBF_u6570_u636E_u52A0_u8F7D" class="headerlink" title="离线数据加载"></a>离线数据加载</h3><h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><ol>
<li>kafka使用文件系统作为持久化介质，为了提高速度采用了顺序读写磁盘的方式。</li>
<li>kafka使用了页面缓存而不是进程内缓存，即可以提高缓存空间又能保证重启的时候缓存不是小。</li>
<li>kafka的写操作使用了sendfile API，它允许在文件描述符之间传输数据，从而减少了不必要的拷贝，提高了效率。</li>
<li>kafka支持批量消息压缩，从而降低对网络带宽的占用。</li>
<li>生产者负载均衡是在客户端实现，生产者直接将数据发送到broker中</li>
<li>kafka中，生产者推数据到broker中，消费者从broker中拉取数据</li>
<li>kafka分区和offset降低了消息状态维护的成本</li>
</ol>
<h2 id="u53C2_u8003_u6587_u6863"><a href="#u53C2_u8003_u6587_u6863" class="headerlink" title="参考文档"></a>参考文档</h2><ol>
<li><a href="http://kafka.apache.org/documentation.html#design" target="_blank" rel="external">kafka设计</a></li>
<li><a href="http://umeng.baijia.baidu.com/article/227913" target="_blank" rel="external">kafka高性能吞吐揭秘</a></li>
<li><a href="https://www.varnish-cache.org/trac/wiki/ArchitectNotes" target="_blank" rel="external">Vanish的以页面缓存为中心的设计</a></li>
<li><a href="http://man7.org/linux/man-pages/man2/sendfile.2.html" target="_blank" rel="external">sendfile API</a></li>
<li><a href="https://www.ibm.com/developerworks/linux/library/j-zerocopy/" target="_blank" rel="external">零拷贝</a></li>
</ol>

      
    </div>
    
    
      <footer class="article-footer">
        
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/Kafka/">Kafka</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/大数据/">大数据</a></li></ul>

      </footer>
    
  </div>
  
</article>


    
      <article id="post-kafka-selflearning-01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/kafka-selflearning-01/">Kafka学习笔记之基础概念及原理</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/blog/kafka-selflearning-01/" class="article-date">
  <time datetime="2016-01-25T12:02:11.000Z" itemprop="datePublished">2016-01-25</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/blog/categories/coding/">编程</a>
  </div>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="u7EC4_u4EF6_u6982_u5FF5"><a href="#u7EC4_u4EF6_u6982_u5FF5" class="headerlink" title="组件概念"></a>组件概念</h3><p>Topic:消息分类<br>Producer:发布消息到kafka集群<br>consumer:订阅Topic并且处理消息<br>broker:组成kafka集群的服务器</p>
<p>kafka客户端与服务端通信是通过TCP协议实现的。</p>
<h3 id="u6570_u636E_u5B58_u50A8"><a href="#u6570_u636E_u5B58_u50A8" class="headerlink" title="数据存储"></a>数据存储</h3><p>一个kafka集群通常包含多个代理（broker)，为了负载均衡，将话题分为多个分区，每个代理存储一个或多个分区。多个producer和comsumer可以同时生产和获取消息。</p>
<p><img src="http://kafka.apache.org/images/log_anatomy.png" alt="kafka分区"><br>如上图：每个Topic对应多个分区，每个分区是一个有序的消息序列，新提交的消息被添加在序列尾部。</p>
<p>每个分区对应一个逻辑日志，物理上，一个日志为相同大小的一组分段文件。每次生产者发布消息到一个分区，代理就将消息追加到最后一个段文件中。当发布的消息数量达到设定值或者经过一段时间之后，段文件真正写入磁盘。写入完成后，消息公开给消费者（只有同步到磁盘之后才会通知消费者？？）。</p>
<p>kafka中的消息没有消息id，而是通过offset(偏移量)来确定消息的位置。这样就避免了维护消息ID到实际消息地址的开销。消费者向代理异步发出拉请求，每个拉请求都包含要消费的消息偏移量。</p>
<p>如图：<br><img src="http://7xo4v8.com1.z0.glb.clouddn.com/%40%2Fima%2F0609012.png" alt="kafka存储结构"></p>
<h3 id="u4F7F_u7528_u5206_u533A_u5B58_u50A8_u6709_u4EC0_u4E48_u597D_u5904_uFF1F"><a href="#u4F7F_u7528_u5206_u533A_u5B58_u50A8_u6709_u4EC0_u4E48_u597D_u5904_uFF1F" class="headerlink" title="使用分区存储有什么好处？"></a>使用分区存储有什么好处？</h3><ol>
<li>允许超过单机允许大小的日志文件存在</li>
<li>多个分区可以提高并行度</li>
</ol>
<h3 id="u5206_u5E03_u5F0F"><a href="#u5206_u5E03_u5F0F" class="headerlink" title="分布式"></a>分布式</h3><p>分区日志分布在kafka集群中的多台机器上，每台机器处理一部分分区。每个分区在多台机器上进行备份以增加容错性。</p>
<p>每个分区只有一个leader机器，0台或者多台follower机器。leader机器处理对该分区的所有读写请求，follower机器负责同步leader机器的数据。如果leader挂掉了，剩下的followers将自动选一台leader。</p>
<p>一台机器作为A分区的follower可以作为B分区的leader，这样就实现了集群内负载均衡。</p>
<h3 id="u6570_u636E_u4F20_u8F93"><a href="#u6570_u636E_u4F20_u8F93" class="headerlink" title="数据传输"></a>数据传输</h3><p>kafka利用sendfile API从代理的日志段文件中分发字节给消费者。<br>sendfile API:<a href="http://man7.org/linux/man-pages/man2/sendfile.2.html" target="_blank" rel="external">http://man7.org/linux/man-pages/man2/sendfile.2.html</a><br>它可以直接在两个文件的描述符之间传输数据，sendfile(）可以将一个文件描述符表示的文件中的数据拷贝到另外的文件描述符中，由于拷贝是在内核中进行的，所以比组合使用read()和write()要快很多，因为后者read和write数据需要经过用户空间。</p>
<h3 id="kafka_u4EE3_u7406_uFF08broker_uFF09"><a href="#kafka_u4EE3_u7406_uFF08broker_uFF09" class="headerlink" title="kafka代理（broker）"></a>kafka代理（broker）</h3><p>kafka代理是无状态的，消费者需要自己维护已消费的状态信息。<br>代理删除消息：代理由于无状态，故它不知道消费者是否已经使用了该消息。Kafka使用基于时间的SLA应用于保留策略。当消息在代理中超过一定时间后，将会被自动删除。</p>
<p>kafka集群会维护所有发布的消息，无论是否被消费过，直到消息过期。过期时间是可以配置的。比如：某个日志被设置为两天，那么消息发布之后两天之内，它都是可以被消费的，但是两天之后，kafka将把消息丢弃以腾出空间。<br>kafka的性能是不受存储数据大小的影响的，所以维护大量数据并不是问题。</p>
<h3 id="zookeeper_u4E0Ekafka"><a href="#zookeeper_u4E0Ekafka" class="headerlink" title="zookeeper与kafka"></a>zookeeper与kafka</h3><p>ZooKeeper在kafka中被用于管理、协调Kafka代理。每个Kafka代理都通过ZooKeeper协调其它Kafka代理。当Kafka系统中新增了代理或者某个代理故障失效时，ZooKeeper服务将通知生产者和消费者。生产者和消费者据此开始与其它代理协调工作。<br><img src="http://7xo4v8.com1.z0.glb.clouddn.com/%40%2Fima%2Fkafka_zk.png" alt="zk在kafka中的应用"></p>
<h3 id="u6D88_u8D39_u8005_u7EC4"><a href="#u6D88_u8D39_u8005_u7EC4" class="headerlink" title="消费者组"></a>消费者组</h3><p>传统消息系统有两种模型：队列模型和发布-订阅模型。<br>队列模型：队列中的每条消息只会发到众多消费者中的一个。<br>发布订阅模型：消息会被广播到所有的消费者。</p>
<p>kafka将消费者抽象出来了“消费者组”的概念，这个概念能够同时实现上述两种模型的功能。</p>
<p>每个消费者属于一个组，消息会被发送到每个组中的某一个消费者实例。<br>注意：每个组中的某一个消费者实例。意思就是，假如我有2个组，A和B，然后有一条消息，这条消息会被发往A和B两个组，但是每个组中只有一个消费者实例能够收到该条消息。所以就有了如下变种：</p>
<p>如果所有的消费者都属于一个组，那么就相当于实现了队列模型。<br>如果每个消费者都属于不同的组，那么就相当于实现了发布-订阅模型。</p>
<h3 id="u6D88_u606F_u987A_u5E8F_u4FDD_u8BC1"><a href="#u6D88_u606F_u987A_u5E8F_u4FDD_u8BC1" class="headerlink" title="消息顺序保证"></a>消息顺序保证</h3><p>kafka提供了很高的消息顺序保证。</p>
<p>传统的消息系统服务器，在服务端按存储顺序维护消息，但是消息发送给消费者是通过异步发送的，所以消息实际到达消费者的顺序就可能与服务端维护的顺序不一致。很多消息系统对此采用的办法就是只允许一个进程消费消息，这样虽然能够保证消息的顺序性，但是却丢失了并发性。</p>
<p>kafka通过将Topic进行分区，很好的提高了并发性，它既能提供顺序保证又能在多个消费者之间做到负载均衡。它是通过绑定主题分区与消费者组中的消费者，从而保证每个分区只能被分区中的一个消费者所消费。这样就能够保证被指定的消费者是唯一一个读取指定分区的消费者，并且该消费者按顺序消费数据。由于存在多个分区，所以仍然不必担心负载均衡的问题。</p>
<p>简单来说就是：kafka是通过保证某一个分区是只被每个组中的一个消费者消费，控制的只是单个分区中消息的顺序。如果你要保证整个Topic的消息顺序，那只需要将分区数设置为1就可以了。</p>
<h3 id="kafka_u63D0_u4F9B_u7684_u4FDD_u8BC1"><a href="#kafka_u63D0_u4F9B_u7684_u4FDD_u8BC1" class="headerlink" title="kafka提供的保证"></a>kafka提供的保证</h3><ul>
<li>生产者发送到某个特定Topic分区的消息将会按照它们的发送顺序依次追加。就是说，如果M1和M2是由同一个生产者发送的消息，M1是先发送的，那么M1在日志中的offset就会比M2低很多。</li>
<li>消费者实例看到消息的顺序与它们在日志中的存储顺序一致。</li>
<li>对于备份因子为N的一个消息主题，可以允许N-1台服务器宕机而不会丢失任何已经提交到日志中的消息。</li>
</ul>
<h3 id="kafka_u7684_u5E94_u7528_u573A_u666F"><a href="#kafka_u7684_u5E94_u7528_u573A_u666F" class="headerlink" title="kafka的应用场景"></a>kafka的应用场景</h3><ol>
<li>消息系统</li>
<li>网站活动追踪</li>
<li>日志收集</li>
<li>流处理（与Storm配合使用）</li>
<li>事件源</li>
<li>日志提交（Bookeeper)</li>
</ol>
<h3 id="u53C2_u8003_u8D44_u6599"><a href="#u53C2_u8003_u8D44_u6599" class="headerlink" title="参考资料"></a>参考资料</h3><ol>
<li><a href="http://www.infoq.com/cn/articles/apache-kafka" target="_blank" rel="external">Apache Kafka：下一代分布式消息系统</a></li>
<li><a href="http://kafka.apache.org/documentation.html#uses" target="_blank" rel="external">Kafka官方文档</a></li>
</ol>

      
    </div>
    
    
      <footer class="article-footer">
        
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/Kafka/">Kafka</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/大数据/">大数据</a></li></ul>

      </footer>
    
  </div>
  
</article>


    
      <article id="post-how-linux-commands-used-in-dubbo" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/how-linux-commands-used-in-dubbo/">Dubbo启动脚本学习</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/blog/how-linux-commands-used-in-dubbo/" class="article-date">
  <time datetime="2016-01-25T11:59:07.000Z" itemprop="datePublished">2016-01-25</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/blog/categories/coding/">编程</a>
  </div>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p>Dubbod启动的脚本：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="shebang">#!/bin/bash</span></span><br><span class="line"><span class="built_in">cd</span> `dirname <span class="variable">$0</span>`</span><br><span class="line">BIN_DIR=`<span class="built_in">pwd</span>`</span><br><span class="line"><span class="built_in">cd</span> ..</span><br><span class="line">DEPLOY_DIR=`<span class="built_in">pwd</span>`</span><br><span class="line">CONF_DIR=<span class="variable">$DEPLOY_DIR</span>/conf</span><br><span class="line"></span><br><span class="line">SERVER_NAME=`sed <span class="string">'/dubbo.application.name/!d;s/.*=//'</span> conf/dubbo.properties | tr <span class="operator">-d</span> <span class="string">'\r'</span>`</span><br><span class="line">SERVER_PROTOCOL=`sed <span class="string">'/dubbo.protocol.name/!d;s/.*=//'</span> conf/dubbo.properties | tr <span class="operator">-d</span> <span class="string">'\r'</span>`</span><br><span class="line">SERVER_PORT=`sed <span class="string">'/dubbo.protocol.port/!d;s/.*=//'</span> conf/dubbo.properties | tr <span class="operator">-d</span> <span class="string">'\r'</span>`</span><br><span class="line">LOGS_FILE=`sed <span class="string">'/dubbo.log4j.file/!d;s/.*=//'</span> conf/dubbo.properties | tr <span class="operator">-d</span> <span class="string">'\r'</span>`</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">"<span class="variable">$SERVER_NAME</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">    SERVER_NAME=`hostname`</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">PIDS=`ps <span class="operator">-f</span> | grep java | grep <span class="string">"<span class="variable">$CONF_DIR</span>"</span> |awk <span class="string">'&#123;print $2&#125;'</span>`</span><br><span class="line"><span class="keyword">if</span> [ -n <span class="string">"<span class="variable">$PIDS</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"ERROR: The <span class="variable">$SERVER_NAME</span> already started!"</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"PID: <span class="variable">$PIDS</span>"</span></span><br><span class="line">    <span class="built_in">exit</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -n <span class="string">"<span class="variable">$SERVER_PORT</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">    SERVER_PORT_COUNT=`netstat -tln | grep <span class="variable">$SERVER_PORT</span> | wc <span class="operator">-l</span>`</span><br><span class="line">    <span class="keyword">if</span> [ <span class="variable">$SERVER_PORT_COUNT</span> <span class="operator">-gt</span> <span class="number">0</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"ERROR: The <span class="variable">$SERVER_NAME</span> port <span class="variable">$SERVER_PORT</span> already used!"</span></span><br><span class="line">        <span class="built_in">exit</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">LOGS_DIR=<span class="string">""</span></span><br><span class="line"><span class="keyword">if</span> [ -n <span class="string">"<span class="variable">$LOGS_FILE</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">    LOGS_DIR=`dirname <span class="variable">$LOGS_FILE</span>`</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    LOGS_DIR=<span class="variable">$DEPLOY_DIR</span>/logs</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">if</span> [ ! <span class="operator">-d</span> <span class="variable">$LOGS_DIR</span> ]; <span class="keyword">then</span></span><br><span class="line">    mkdir <span class="variable">$LOGS_DIR</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">STDOUT_FILE=<span class="variable">$LOGS_DIR</span>/stdout.log</span><br><span class="line"></span><br><span class="line">LIB_DIR=<span class="variable">$DEPLOY_DIR</span>/lib</span><br><span class="line">LIB_JARS=`ls <span class="variable">$LIB_DIR</span>|grep .jar|awk <span class="string">'&#123;print "'</span><span class="variable">$LIB_DIR</span><span class="string">'/"$0&#125;'</span>|tr <span class="string">"\n"</span> <span class="string">":"</span>`</span><br><span class="line"></span><br><span class="line">JAVA_OPTS=<span class="string">" -Djava.awt.headless=true -Djava.net.preferIPv4Stack=true "</span></span><br><span class="line">JAVA_DEBUG_OPTS=<span class="string">""</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$1</span>"</span> = <span class="string">"debug"</span> ]; <span class="keyword">then</span></span><br><span class="line">    JAVA_DEBUG_OPTS=<span class="string">" -Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,address=8000,server=y,suspend=n "</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">JAVA_JMX_OPTS=<span class="string">""</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$1</span>"</span> = <span class="string">"jmx"</span> ]; <span class="keyword">then</span></span><br><span class="line">    JAVA_JMX_OPTS=<span class="string">" -Dcom.sun.management.jmxremote.port=1099 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false "</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">JAVA_MEM_OPTS=<span class="string">""</span></span><br><span class="line">BITS=`java -version <span class="number">2</span>&gt;&amp;<span class="number">1</span> | grep -i <span class="number">64</span>-bit`</span><br><span class="line"><span class="keyword">if</span> [ -n <span class="string">"<span class="variable">$BITS</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">    JAVA_MEM_OPTS=<span class="string">" -server -Xmx2g -Xms2g -Xmn256m -XX:PermSize=128m -Xss256k -XX:+DisableExplicitGC -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:+UseCMSCompactAtFullCollection -XX:LargePageSizeInBytes=128m -XX:+UseFastAccessorMethods -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=70 "</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    JAVA_MEM_OPTS=<span class="string">" -server -Xms1g -Xmx1g -XX:PermSize=128m -XX:SurvivorRatio=2 -XX:+UseParallelGC "</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="operator">-e</span> <span class="string">"Starting the <span class="variable">$SERVER_NAME</span> ...\c"</span></span><br><span class="line">nohup java <span class="variable">$JAVA_OPTS</span> <span class="variable">$JAVA_MEM_OPTS</span> <span class="variable">$JAVA_DEBUG_OPTS</span> <span class="variable">$JAVA_JMX_OPTS</span> -classpath <span class="variable">$CONF_DIR</span>:<span class="variable">$LIB_JARS</span> com.alibaba.dubbo.container.Main &gt; <span class="variable">$STDOUT_FILE</span> <span class="number">2</span>&gt;&amp;<span class="number">1</span> &amp;</span><br><span class="line"></span><br><span class="line">COUNT=<span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> [ <span class="variable">$COUNT</span> <span class="operator">-lt</span> <span class="number">1</span> ]; <span class="keyword">do</span>    </span><br><span class="line">    <span class="built_in">echo</span> <span class="operator">-e</span> <span class="string">".\c"</span></span><br><span class="line">    sleep <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> [ -n <span class="string">"<span class="variable">$SERVER_PORT</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="keyword">if</span> [ <span class="string">"<span class="variable">$SERVER_PROTOCOL</span>"</span> == <span class="string">"dubbo"</span> ]; <span class="keyword">then</span></span><br><span class="line">    	    COUNT=`<span class="built_in">echo</span> status | nc -i <span class="number">1</span> <span class="number">127.0</span>.<span class="number">0.1</span> <span class="variable">$SERVER_PORT</span> | grep -c OK`</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            COUNT=`netstat -an | grep <span class="variable">$SERVER_PORT</span> | wc <span class="operator">-l</span>`</span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    	COUNT=`ps <span class="operator">-f</span> | grep java | grep <span class="string">"<span class="variable">$DEPLOY_DIR</span>"</span> | awk <span class="string">'&#123;print $2&#125;'</span> | wc <span class="operator">-l</span>`</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">if</span> [ <span class="variable">$COUNT</span> <span class="operator">-gt</span> <span class="number">0</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">break</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"OK!"</span></span><br><span class="line">PIDS=`ps <span class="operator">-f</span> | grep java | grep <span class="string">"<span class="variable">$DEPLOY_DIR</span>"</span> | awk <span class="string">'&#123;print $2&#125;'</span>`</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"PID: <span class="variable">$PIDS</span>"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"STDOUT: <span class="variable">$STDOUT_FILE</span>"</span></span><br></pre></td></tr></table></figure></p>
<p>下面是简单的解释：</p>
<p>startserver.sh<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="shebang">#!/bin/bash</span></span><br><span class="line"><span class="built_in">cd</span> `dirname <span class="variable">$0</span>`</span><br></pre></td></tr></table></figure></p>
<p>$0当前Shell程序的文件名<br>dirname $0，获取当前Shell程序的路径<br>cd <code>dirname $0</code>，进入当前Shell程序的目录</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SERVER_NAME=`sed <span class="string">'/dubbo.application.name/!d;s/.*=//'</span> conf/dubbo.properties | tr <span class="operator">-d</span> <span class="string">'\r'</span>`</span><br></pre></td></tr></table></figure>
<p><code>sed &#39;/dubbo.application.name/!d;s/.*=//&#39; ../conf/dubbo.properties</code> 从conf/dubbo.properties文件中截取dubbo.application.name对应的值</p>
<p><code>sed &#39;/dubbo.application.name/!d&#39; dubbo.properties</code> 从dubbo.properties文件中查找包含dubbo.application.name的行，<code>!d</code>表示不删除，这样执行完的结果是：<br><code>ubbo.application.name=my-server</code></p>
<p>后面的：<code>;s/.*=//</code> 表示替换，即将所得数据中的 ‘.*=’部分，替换成掉。<br>结果：<br><code>my-server</code> 即，只有我的服务名称了</p>
<p><code>tr -d &#39;\r&#39;</code> 将回车符号删除</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [ -z <span class="string">"<span class="variable">$SERVER_NAME</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">    SERVER_NAME=`hostname`</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<p>if  [ -z $string  ]             如果string 为空</p>
<p><code>hostname</code> 显示当前系统的hostname</p>
<blockquote>
<p>hostname - show or set the system’s host name<br>       domainname - show or set the system’s NIS/YP domain name<br>       dnsdomainname - show the system’s DNS domain name<br>       nisdomainname - show or set system’s NIS/YP domain name<br>       ypdomainname - show or set the system’s NIS/YP domain name</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PIDS=`ps <span class="operator">-f</span> | grep java | grep <span class="string">"<span class="variable">$CONF_DIR</span>"</span> |awk <span class="string">'&#123;print $2&#125;'</span>`</span><br></pre></td></tr></table></figure>
<p><code>ps -f | grep java | grep &quot;$CONF_DIR&quot;</code> 根据配置文件路径定位到当前服务的进程id。格式如下<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root     <span class="number">25867</span>     <span class="number">1</span>  <span class="number">0</span> Jan04 ?        <span class="number">00</span>:<span class="number">37</span>:<span class="number">35</span> java -Djava.awt.headless=<span class="literal">true</span> -Djava.net.preferIPv4Stack=<span class="literal">true</span> -server -Xmx2g -Xms2g -Xmn256m -XX:PermSize=<span class="number">128</span>m -Xss256k -XX:+DisableExplicitGC -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:+UseCMSCompa...</span><br></pre></td></tr></table></figure></p>
<p>此时调用<code>awk &#39;{print $2}&#39;</code>，则将第二列打印出来，正好是当前进行的进程id。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [ -n <span class="string">"<span class="variable">$PIDS</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"ERROR: The <span class="variable">$SERVER_NAME</span> already started!"</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"PID: <span class="variable">$PIDS</span>"</span></span><br><span class="line">    <span class="built_in">exit</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<p>if  [ -n $string  ]             如果string 非空(非0），返回0(true)<br>若果当前进程存在，则输出：已经启动</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [ -n <span class="string">"<span class="variable">$SERVER_PORT</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">    SERVER_PORT_COUNT=`netstat -tln | grep <span class="variable">$SERVER_PORT</span> | wc <span class="operator">-l</span>`</span><br><span class="line">    <span class="keyword">if</span> [ <span class="variable">$SERVER_PORT_COUNT</span> <span class="operator">-gt</span> <span class="number">0</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"ERROR: The <span class="variable">$SERVER_NAME</span> port <span class="variable">$SERVER_PORT</span> already used!"</span></span><br><span class="line">        <span class="built_in">exit</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<p>如果端口号不为空，则通过<br><code>netstat -tln | grep $SERVER_PORT | wc -l</code> 来统计当前已经占用该端口的数量<br>如果数量大于0.则提示端口被占用。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">LOGS_DIR=<span class="string">""</span></span><br><span class="line"><span class="keyword">if</span> [ -n <span class="string">"<span class="variable">$LOGS_FILE</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">    LOGS_DIR=`dirname <span class="variable">$LOGS_FILE</span>`</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    LOGS_DIR=<span class="variable">$DEPLOY_DIR</span>/logs</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">if</span> [ ! <span class="operator">-d</span> <span class="variable">$LOGS_DIR</span> ]; <span class="keyword">then</span></span><br><span class="line">    mkdir <span class="variable">$LOGS_DIR</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<p>if [ ! -d $LOGS_DIR ] 如果日志目录不存在，就创建该目录</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">LIB_DIR=<span class="variable">$DEPLOY_DIR</span>/lib</span><br><span class="line">LIB_JARS=`ls <span class="variable">$LIB_DIR</span>|grep .jar|awk <span class="string">'&#123;print "'</span><span class="variable">$LIB_DIR</span><span class="string">'/"$0&#125;'</span>|tr <span class="string">"\n"</span> <span class="string">":"</span>`</span><br></pre></td></tr></table></figure>
<p>获取lib目录下的jar包。</p>
<p><code>ls $LIB_DIR|grep .jar|</code> 获取lib目录下的所有.jar文件名称。<br><code>awk &#39;{print &quot;&#39;$LIB_DIR&#39;/&quot;$0}</code> 将上面的jar文件名称，拼接上lib的路径然后输出。</p>
<p><code>tr &quot;\n&quot; &quot;:&quot;</code> 将换行符替换成冒号。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">JAVA_OPTS=<span class="string">" -Djava.awt.headless=true -Djava.net.preferIPv4Stack=true "</span></span><br><span class="line">JAVA_DEBUG_OPTS=<span class="string">""</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$1</span>"</span> = <span class="string">"debug"</span> ]; <span class="keyword">then</span></span><br><span class="line">    JAVA_DEBUG_OPTS=<span class="string">" -Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,address=8000,server=y,suspend=n "</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">JAVA_JMX_OPTS=<span class="string">""</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$1</span>"</span> = <span class="string">"jmx"</span> ]; <span class="keyword">then</span></span><br><span class="line">    JAVA_JMX_OPTS=<span class="string">" -Dcom.sun.management.jmxremote.port=1099 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false "</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">JAVA_MEM_OPTS=<span class="string">""</span></span><br><span class="line">BITS=`java -version <span class="number">2</span>&gt;&amp;<span class="number">1</span> | grep -i <span class="number">64</span>-bit`</span><br><span class="line"><span class="keyword">if</span> [ -n <span class="string">"<span class="variable">$BITS</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">    JAVA_MEM_OPTS=<span class="string">" -server -Xmx2g -Xms2g -Xmn256m -XX:PermSize=128m -Xss256k -XX:+DisableExplicitGC -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:+UseCMSCompactAtFullCollection -XX:LargePageSizeInBytes=128m -XX:+UseFastAccessorMethods -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=70 "</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    JAVA_MEM_OPTS=<span class="string">" -server -Xms1g -Xmx1g -XX:PermSize=128m -XX:SurvivorRatio=2 -XX:+UseParallelGC "</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="operator">-e</span> <span class="string">"Starting the <span class="variable">$SERVER_NAME</span> ...\c"</span></span><br><span class="line">nohup java <span class="variable">$JAVA_OPTS</span> <span class="variable">$JAVA_MEM_OPTS</span> <span class="variable">$JAVA_DEBUG_OPTS</span> <span class="variable">$JAVA_JMX_OPTS</span> -classpath <span class="variable">$CONF_DIR</span>:<span class="variable">$LIB_JARS</span> com.alibaba.dubbo.container.Main &gt; <span class="variable">$STDOUT_FILE</span> <span class="number">2</span>&gt;&amp;<span class="number">1</span> &amp;</span><br></pre></td></tr></table></figure>
<p><code>java -version 2&gt;&amp;1 | grep -i 64-bit</code>这里，首先将java版本号信息输出到标准输出，然后查找’64-bit’信息，目的就是判断jdk版本是否为64位。</p>
<p><code>nohup java $JAVA_OPTS $JAVA_MEM_OPTS $JAVA_DEBUG_OPTS $JAVA_JMX_OPTS -classpath $CONF_DIR:$LIB_JARS com.alibaba.dubbo.container.Main &gt; $STDOUT_FILE 2&gt;&amp;1 &amp;</code> 通过java命令启动服务，同时将其作为后台任务执行。</p>
<p>关于 <code>2&gt;&amp;1</code> 可以看：<a href="http://blog.sina.com.cn/s/blog_4aae007d010192qc.html" target="_blank" rel="external">http://blog.sina.com.cn/s/blog_4aae007d010192qc.html</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">COUNT=<span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> [ <span class="variable">$COUNT</span> <span class="operator">-lt</span> <span class="number">1</span> ]; <span class="keyword">do</span>   </span><br><span class="line">    <span class="built_in">echo</span> <span class="operator">-e</span> <span class="string">".\c"</span></span><br><span class="line">    sleep <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> [ -n <span class="string">"<span class="variable">$SERVER_PORT</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="keyword">if</span> [ <span class="string">"<span class="variable">$SERVER_PROTOCOL</span>"</span> == <span class="string">"dubbo"</span> ]; <span class="keyword">then</span></span><br><span class="line">            COUNT=`<span class="built_in">echo</span> status | nc -i <span class="number">1</span> <span class="number">127.0</span>.<span class="number">0.1</span> <span class="variable">$SERVER_PORT</span> | grep -c OK`</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            COUNT=`netstat -an | grep <span class="variable">$SERVER_PORT</span> | wc <span class="operator">-l</span>`</span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        COUNT=`ps <span class="operator">-f</span> | grep java | grep <span class="string">"<span class="variable">$DEPLOY_DIR</span>"</span> | awk <span class="string">'&#123;print $2&#125;'</span> | wc <span class="operator">-l</span>`</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">if</span> [ <span class="variable">$COUNT</span> <span class="operator">-gt</span> <span class="number">0</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">break</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<p><code>echo -e &quot;.\c&quot;</code><br><code>echo status | nc -i 1 127.0.0.1 $SERVER_PORT | grep -c OK</code></p>
<p>grep -c 阻止正常的结果输出，转而输出匹配的结果数量，这里就是输出OK的个数。</p>

      
    </div>
    
    
      <footer class="article-footer">
        
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/Dubbo/">Dubbo</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/linux/">linux</a></li></ul>

      </footer>
    
  </div>
  
</article>


    
      <article id="post-murmurhash" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/murmurhash/">Murmur哈希算法</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/blog/murmurhash/" class="article-date">
  <time datetime="2016-01-25T11:51:27.000Z" itemprop="datePublished">2016-01-25</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/blog/categories/coding/">编程</a>
  </div>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p>在看<a href="http://redisbook.com/preview/dict/hash_algorithm.html" target="_blank" rel="external">redis哈希</a>的时候发现了这个算法。</p>
<h2 id="u4F5C_u7528"><a href="#u4F5C_u7528" class="headerlink" title="作用"></a>作用</h2><p>MurmurHash是一种非加密型哈希函数。与其他流行的哈希函数相比，对于规律性较强的key，MurmurHash的随机分布特征表现更良好。</p>
<p>最早发明与2008年，目前的版本是MurmurHash3,可以产生32位或者128位的哈希值。其名字来自于MUltiply and Rotate,因为要经过多次MUltiply and Rotate，所以叫Murmur.</p>
<h2 id="u5B9E_u73B0"><a href="#u5B9E_u73B0" class="headerlink" title="实现"></a>实现</h2><p>在java中，Guava的Hashing类中提供了多个版本的实现。<br><a href="https://github.com/google/guava/blob/master/guava/src/com/google/common/hash/Murmur3_32HashFunction.java" target="_blank" rel="external">32位版本</a><br><a href="https://github.com/google/guava/blob/master/guava%2Fsrc%2Fcom%2Fgoogle%2Fcommon%2Fhash%2FMurmur3_128HashFunction.java" target="_blank" rel="external">128位版本</a></p>
<p>另外，很多应用广泛的开源产品也使用了MurmurHash<br><a href="https://github.com/xetorthio/jedis/blob/master/src/main/java/redis/clients/util/MurmurHash.java" target="_blank" rel="external">jedis的MurmurHash</a><br><a href="https://github.com/xetorthio/jedis/blob/master/src/main/java/redis/clients/util/MurmurHash.java" target="_blank" rel="external">cassandra的MurmurHash实现</a><br><a href="https://github.com/apache/hbase/blob/a545d71295e582398b2689ed09d2167d7f118cec/hbase-common/src/main/java/org/apache/hadoop/hbase/util/MurmurHash3.java" target="_blank" rel="external">Hbase中的Murmurhash</a><br><a href="https://lucene.apache.org/core/4_8_0/codecs/org/apache/lucene/codecs/bloom/MurmurHash2.html" target="_blank" rel="external">Lucene中的murmurhsah</a></p>
<h2 id="u76F8_u5173_u6587_u6863"><a href="#u76F8_u5173_u6587_u6863" class="headerlink" title="相关文档"></a>相关文档</h2><ol>
<li><a href="http://redisbook.com/preview/dict/hash_algorithm.html" target="_blank" rel="external">redis hash</a></li>
<li><a href="https://zh.wikipedia.org/zh-cn/Murmur%E5%93%88%E5%B8%8C" target="_blank" rel="external">murmur哈希wiki</a></li>
<li><a href="http://calvin1978.blogcn.com/articles/murmur.html" target="_blank" rel="external">陌生但默默一统江湖的MurmurHash</a></li>
<li><a href="http://openwares.net/misc/murmurhash%E7%AE%97%E6%B3%95.html" target="_blank" rel="external">murmurhash算法</a></li>
</ol>

      
    </div>
    
    
      <footer class="article-footer">
        
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/哈希算法/">哈希算法</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/算法/">算法</a></li></ul>

      </footer>
    
  </div>
  
</article>


    
      <article id="post-cryptology" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/cryptology/">密码学综述</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/blog/cryptology/" class="article-date">
  <time datetime="2016-01-25T11:49:15.000Z" itemprop="datePublished">2016-01-25</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/blog/categories/coding/">编程</a>
  </div>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="u5BC6_u7801_u5B66_u7B97_u6CD5_u7684_u5206_u7C7B"><a href="#u5BC6_u7801_u5B66_u7B97_u6CD5_u7684_u5206_u7C7B" class="headerlink" title="密码学算法的分类"></a>密码学算法的分类</h2><ul>
<li>消息编码：base64</li>
<li>消息摘要：MD类，SHA类，MAC</li>
<li>对称密码: DES,3DES,AES</li>
<li>非对称密码：RSA，DH秘钥交换</li>
<li>数字签名：RSASignature，DSASignature</li>
</ul>
<h2 id="u5BC6_u7801_u5B665_u5143_u7956"><a href="#u5BC6_u7801_u5B665_u5143_u7956" class="headerlink" title="密码学5元祖"></a>密码学5元祖</h2><p>（明文，密文，加密算法，解密算法，密钥）<br>加密算法和解密算法都是公开的。使用保密的加密算法和解密算法是不够安全的，而且也很难做到保密工作）</p>
<p>安全性完全依赖于秘钥。</p>
<p>密码与密钥<br>密码=秘钥+规则<br>秘钥才是需要保证绝密的。</p>
<h2 id="u5BF9_u79F0_u5BC6_u7801_u4E0E_u975E_u5BF9_u79F0_u5BC6_u7801"><a href="#u5BF9_u79F0_u5BC6_u7801_u4E0E_u975E_u5BF9_u79F0_u5BC6_u7801" class="headerlink" title="对称密码与非对称密码"></a>对称密码与非对称密码</h2><p>对称密码：加密和解密使用相同的秘钥<br>非对称：加密和解密是用不同的秘钥。</p>
<p>两者不能相互取代，也无法区分哪个更安全。是否更安全主要取决于秘钥的长度以及破译密文所需要的计算量。</p>
<h2 id="java_u4E2D_u7684_u7C7B"><a href="#java_u4E2D_u7684_u7C7B" class="headerlink" title="java中的类"></a>java中的类</h2><ol>
<li>消息编码：BASE64Encoder,BASE64Decoder</li>
<li>消息摘要：MessageDigest</li>
<li>对称密码：KeyGenerator，SecretKey，Cipher</li>
<li>非对称密码：KeyPairGenerator,KeyFactory,KeyPair,PublicKey,PrivateKey,Cipher</li>
<li>数字签名：Signature</li>
</ol>
<h2 id="Base64_u7684_u7F16_u7A0B_u4F7F_u7528"><a href="#Base64_u7684_u7F16_u7A0B_u4F7F_u7528" class="headerlink" title="Base64的编程使用"></a>Base64的编程使用</h2><h3 id="Base64_u7B97_u6CD5_u5B9A_u4E49"><a href="#Base64_u7B97_u6CD5_u5B9A_u4E49" class="headerlink" title="Base64算法定义"></a>Base64算法定义</h3><p>是一种基于64个字符的编码算法，以任意8位字节序列组合的描述形式，这种形式不容易直接识别。<br>Base64秘钥：就是Base64字符映射表。</p>
<h3 id="Base64_u7F16_u7A0B_u4F7F_u7528"><a href="#Base64_u7F16_u7A0B_u4F7F_u7528" class="headerlink" title="Base64编程使用"></a>Base64编程使用</h3><p><img src="http://7xo4v8.com1.z0.glb.clouddn.com/base64.png" alt="Base64编程使用"></p>
<p>jdk本身没有自带，需要导入sun提供的BASE64相关jar包。</p>
<h3 id="Base64_u7B97_u6CD5_u7684_u5B9E_u9645_u5E94_u7528"><a href="#Base64_u7B97_u6CD5_u7684_u5B9E_u9645_u5E94_u7528" class="headerlink" title="Base64算法的实际应用"></a>Base64算法的实际应用</h3><p>最早被用在电子邮件中，由于邮件只允许传输ASCII码，所以需要用Base64编码。通过telnet远程登录邮箱可以看到使用Base64编码的账号和密码等信息。</p>
<h2 id="u53C2_u8003_u8D44_u6599"><a href="#u53C2_u8003_u8D44_u6599" class="headerlink" title="参考资料"></a>参考资料</h2><p>极客学院课程</p>

      
    </div>
    
    
      <footer class="article-footer">
        
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/密码学/">密码学</a></li></ul>

      </footer>
    
  </div>
  
</article>


    
      <nav id="page-nav">
        <span class="page-number current">1</span><a class="page-number" href="/blog/page/2/">2</a><a class="page-number" href="/blog/page/3/">3</a><a class="page-number" href="/blog/page/4/">4</a><a class="extend next" rel="next" href="/blog/page/2/">下一页 &raquo;</a>
      </nav>
    </section>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Medusar&nbsp;
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, theme by <a href="http://github.com/ppoffice">PPOffice</a>
    </div>
  </div>
</footer>
    

<script src="/blog/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/blog/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/blog/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/blog/js/script.js" type="text/javascript"></script>
  </div>
</body>
</html>